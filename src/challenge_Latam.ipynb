{
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "**Lo primero es cargar el archivo json para utilizar su ruta para poder leer el archivo y obtener los datos.** **FUNDAMENTAL**"
      ],
      "metadata": {
        "id": "E7SgAyYYQXwO"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "id": "xOtsGa2zqSTX"
      },
      "outputs": [],
      "source": [
        "file_path = \"farmers-protest-tweets-2021-2-4.json\""
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Las top 10 fechas donde hay más tweets.**"
      ],
      "metadata": {
        "id": "CCq6hKNhioIR"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Desarrollo de Q1 optimizando el tiempo de ejecucion\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "gwUjsR-mr4YF"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import json\n",
        "from collections import defaultdict\n",
        "from datetime import datetime, date\n",
        "from typing import List, Tuple\n",
        "\n",
        "def q1_time(file_path: str) -> List[Tuple[date, str]]:\n",
        "    date_tweet_counts = defaultdict(lambda: defaultdict(int))\n",
        "\n",
        "    with open(file_path, 'r', encoding='utf-8') as f:\n",
        "        for line in f:\n",
        "            try:\n",
        "                tweet = json.loads(line)\n",
        "                if 'user' in tweet and 'date' in tweet:\n",
        "                    tweet_date = datetime.strptime(tweet['date'], \"%Y-%m-%dT%H:%M:%S%z\").date()\n",
        "                    username = tweet['user']['username']\n",
        "                    date_tweet_counts[tweet_date][username] += 1\n",
        "            except (json.JSONDecodeError, KeyError):\n",
        "                continue\n",
        "\n",
        "    top_10_dates = sorted(date_tweet_counts.keys(), key=lambda x: sum(date_tweet_counts[x].values()), reverse=True)[:10]\n",
        "\n",
        "    result = [(tweet_date, max(date_tweet_counts[tweet_date].items(), key=lambda x: x[1])[0]) for tweet_date in top_10_dates]\n",
        "\n",
        "    return result\n",
        "\n",
        "file_path = \"farmers-protest-tweets-2021-2-4.json\"\n",
        "try:\n",
        "    top_10_dates_users = q1_time(file_path)\n",
        "    print(top_10_dates_users)\n",
        "except FileNotFoundError:\n",
        "    print(f\"File not found: {file_path}. Please check the file path and try again.\")\n",
        "except json.JSONDecodeError as e:\n",
        "    print(f\"Error parsing JSON file: {e}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QtbIFzQLr3sf",
        "outputId": "812e485c-2938-4cbd-a2cd-0ec5c72a5c25"
      },
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[(datetime.date(2021, 2, 12), 'RanbirS00614606'), (datetime.date(2021, 2, 13), 'MaanDee08215437'), (datetime.date(2021, 2, 17), 'RaaJVinderkaur'), (datetime.date(2021, 2, 16), 'jot__b'), (datetime.date(2021, 2, 14), 'rebelpacifist'), (datetime.date(2021, 2, 18), 'neetuanjle_nitu'), (datetime.date(2021, 2, 15), 'jot__b'), (datetime.date(2021, 2, 20), 'MangalJ23056160'), (datetime.date(2021, 2, 23), 'Surrypuria'), (datetime.date(2021, 2, 19), 'Preetm91')]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Desarrollo de Q1 optimizando el uso de memoria\n",
        "\n"
      ],
      "metadata": {
        "id": "AGhXP0JvQIZY"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install memory_profiler"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "koWNMvtoa_4F",
        "outputId": "d73b3527-7db7-4135-d818-6da4562e8a14",
        "collapsed": true
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting memory_profiler\n",
            "  Downloading memory_profiler-0.61.0-py3-none-any.whl (31 kB)\n",
            "Requirement already satisfied: psutil in /usr/local/lib/python3.10/dist-packages (from memory_profiler) (5.9.5)\n",
            "Installing collected packages: memory_profiler\n",
            "Successfully installed memory_profiler-0.61.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import json\n",
        "from collections import defaultdict\n",
        "from datetime import datetime, date\n",
        "from typing import List, Tuple\n",
        "from memory_profiler import profile\n",
        "\n",
        "@profile\n",
        "def q1_memory(file_path: str) -> List[Tuple[date, str]]:\n",
        "    date_tweet_counts = defaultdict(lambda: defaultdict(int))\n",
        "\n",
        "    with open(file_path, 'r', encoding='utf-8') as f:\n",
        "        for line in f:\n",
        "            try:\n",
        "                tweet = json.loads(line)\n",
        "                tweet_date = datetime.strptime(tweet['date'], \"%Y-%m-%dT%H:%M:%S%z\").date()\n",
        "                username = tweet['user']['username']\n",
        "                date_tweet_counts[tweet_date][username] += 1\n",
        "            except (json.JSONDecodeError, KeyError, ValueError) as e:\n",
        "                continue\n",
        "\n",
        "    top_10_dates = sorted(date_tweet_counts.items(), key=lambda x: sum(x[1].values()), reverse=True)[:10]\n",
        "    result = [(tweet_date, max(users.items(), key=lambda x: x[1])[0]) for tweet_date, users in top_10_dates]\n",
        "\n",
        "    return result\n",
        "\n",
        "file_path = \"farmers-protest-tweets-2021-2-4.json\"\n",
        "try:\n",
        "    top_10_dates_users = q1_memory(file_path)\n",
        "    print(top_10_dates_users)\n",
        "except FileNotFoundError:\n",
        "    print(f\"File not found: {file_path}. Please check the file path and try again.\")\n",
        "except json.JSONDecodeError as e:\n",
        "    print(f\"Error parsing JSON file: {e}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TtPvZz2hdkO4",
        "outputId": "98c247c5-b767-41b8-febf-dee04fd86107",
        "collapsed": true
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "PYDEV DEBUGGER WARNING:\n",
            "sys.settrace() should not be used when the debugger is being used.\n",
            "This may cause the debugger to stop working correctly.\n",
            "If this is needed, please check: \n",
            "http://pydev.blogspot.com/2007/06/why-cant-pydev-debugger-work-with.html\n",
            "to see how to restore the debug tracing back correctly.\n",
            "Call Location:\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/memory_profiler.py\", line 847, in enable\n",
            "    sys.settrace(self.trace_memory_usage)\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "ERROR: Could not find file <ipython-input-6-5714df6985c6>\n",
            "NOTE: %mprun can only be used on functions defined in physical files, and not in the IPython environment.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "PYDEV DEBUGGER WARNING:\n",
            "sys.settrace() should not be used when the debugger is being used.\n",
            "This may cause the debugger to stop working correctly.\n",
            "If this is needed, please check: \n",
            "http://pydev.blogspot.com/2007/06/why-cant-pydev-debugger-work-with.html\n",
            "to see how to restore the debug tracing back correctly.\n",
            "Call Location:\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/memory_profiler.py\", line 850, in disable\n",
            "    sys.settrace(self._original_trace_function)\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[(datetime.date(2021, 2, 12), 'RanbirS00614606'), (datetime.date(2021, 2, 13), 'MaanDee08215437'), (datetime.date(2021, 2, 17), 'RaaJVinderkaur'), (datetime.date(2021, 2, 16), 'jot__b'), (datetime.date(2021, 2, 14), 'rebelpacifist'), (datetime.date(2021, 2, 18), 'neetuanjle_nitu'), (datetime.date(2021, 2, 15), 'jot__b'), (datetime.date(2021, 2, 20), 'MangalJ23056160'), (datetime.date(2021, 2, 23), 'Surrypuria'), (datetime.date(2021, 2, 19), 'Preetm91')]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Los top 10 emojis más usados con su respectivo conteo.**"
      ],
      "metadata": {
        "id": "qWcIQku5iuID"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Desarrollo de Q2 optimizando el tiempo de ejecucion\n"
      ],
      "metadata": {
        "id": "mHGCqwuphlW6"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install emoji==1.7"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mLs1L6yHjjIU",
        "outputId": "f2f47845-7c54-4056-e031-cb9c6a78e41a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: emoji==1.7 in /usr/local/lib/python3.10/dist-packages (1.7.0)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import json\n",
        "import re\n",
        "from collections import defaultdict\n",
        "from typing import List, Tuple\n",
        "\n",
        "def q2_time(file_path: str) -> List[Tuple[str, int]]:\n",
        "    emoji_counts = defaultdict(int)\n",
        "    emoji_pattern = re.compile(r'[\\U0001F300-\\U0001F64F]|[\\U0001F680-\\U0001F6FF]|[\\U0001F700-\\U0001F77F]|[\\U0001F780-\\U0001F7FF]|[\\U0001F800-\\U0001F8FF]', flags=re.UNICODE)\n",
        "\n",
        "    with open(file_path, 'r', encoding='utf-8') as f:\n",
        "        for line in f:\n",
        "            try:\n",
        "                tweet = json.loads(line)\n",
        "                if 'content' in tweet:\n",
        "                    emojis = emoji_pattern.findall(tweet['content'])\n",
        "                    for emoji in emojis:\n",
        "                        emoji_counts[emoji] += 1\n",
        "            except (json.JSONDecodeError, KeyError):\n",
        "                continue\n",
        "\n",
        "    top_10_emojis = sorted(emoji_counts.items(), key=lambda x: x[1], reverse=True)[:10]\n",
        "    return top_10_emojis\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    file_path = \"farmers-protest-tweets-2021-2-4.json\"\n",
        "    try:\n",
        "        top_10_emojis = q2_time(file_path)\n",
        "        print(top_10_emojis)\n",
        "    except FileNotFoundError:\n",
        "        print(f\"File not found: {file_path}. Please check the file path and try again.\")\n",
        "    except json.JSONDecodeError as e:\n",
        "        print(f\"Error parsing JSON file: {e}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZKCovt3ahrpn",
        "outputId": "af8773a2-5063-4747-eca9-7e29bee96ae3"
      },
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[('🙏', 7286), ('😂', 3072), ('🚜', 2972), ('🌾', 2363), ('🏻', 2080), ('🏽', 1218), ('👇', 1108), ('💚', 1040), ('💪', 947), ('🏼', 857)]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Desarrollo de Q2 optimizando el uso de memoria"
      ],
      "metadata": {
        "id": "ogHv4MoKhtnF"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from collections import defaultdict\n",
        "from typing import List, Tuple\n",
        "from emoji import UNICODE_EMOJI\n",
        "from memory_profiler import profile\n",
        "\n",
        "def is_emoji(char: str) -> bool:\n",
        "    # Validar si el carácter es un emoji Unicode (Optimiza el uso de memoria al interpretar emojis directamente con la libreria)\n",
        "    return char in UNICODE_EMOJI['en']\n",
        "\n",
        "@profile\n",
        "def q2_memory(file_path: str) -> List[Tuple[str, int]]:\n",
        "    emoji_counts = defaultdict(int)\n",
        "    emoji_pattern = re.compile(r'[\\U0001F000-\\U0001FFFF]|[\\U00002000-\\U00003FFF]', flags=re.UNICODE)  # Patrón para emojis Unicode\n",
        "\n",
        "    with open(file_path, 'r', encoding='utf-8') as f:\n",
        "        for line in f:\n",
        "            try:\n",
        "                tweet = json.loads(line)\n",
        "                if 'content' in tweet:\n",
        "                    emojis = emoji_pattern.findall(tweet['content'])\n",
        "                    valid_emojis = filter(is_emoji, emojis)  # Filtrar solo emojis válidos\n",
        "                    for emoji in valid_emojis:\n",
        "                        emoji_counts[emoji] += 1\n",
        "            except (json.JSONDecodeError, KeyError):\n",
        "                continue\n",
        "\n",
        "    top_10_emojis = sorted(emoji_counts.items(), key=lambda x: x[1], reverse=True)[:10]\n",
        "    return top_10_emojis\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    file_path = \"farmers-protest-tweets-2021-2-4.json\"\n",
        "    try:\n",
        "        top_10_emojis = q2_memory(file_path)\n",
        "        print(top_10_emojis)\n",
        "    except FileNotFoundError:\n",
        "        print(f\"File not found: {file_path}. Please check the file path and try again.\")\n",
        "    except json.JSONDecodeError as e:\n",
        "        print(f\"Error parsing JSON file: {e}\")\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "X2sPFaBehyHa",
        "outputId": "7332cae3-2334-4392-cf9d-599ea2469a3c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "ERROR: Could not find file <ipython-input-8-5134f60780bc>\n",
            "NOTE: %mprun can only be used on functions defined in physical files, and not in the IPython environment.\n",
            "[('🙏', 7286), ('😂', 3072), ('🚜', 2972), ('✊', 2411), ('🌾', 2363), ('🏻', 2080), ('❤', 1779), ('🤣', 1668), ('🏽', 1218), ('👇', 1108)]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**El top 10 histórico de usuarios (username) más influyentes en función del conteo de las menciones (@) que registra cada uno de ellos.**\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "yO3xlEirX_ic"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Desarrollo de Q3 optimizando el tiempo de ejecucion\n"
      ],
      "metadata": {
        "id": "PKsKWEJahr9r"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import json\n",
        "from collections import defaultdict\n",
        "import re\n",
        "from typing import List, Tuple\n",
        "\n",
        "def extract_mentions(text: str) -> List[str]:\n",
        "    # Utilizamos regex para encontrar menciones (@username)\n",
        "    mention_pattern = re.compile(r'@(\\w+)')\n",
        "    return mention_pattern.findall(text)\n",
        "\n",
        "def q3_time(file_path: str) -> List[Tuple[str, int]]:\n",
        "    mention_counts = defaultdict(int)\n",
        "\n",
        "    with open(file_path, 'r', encoding='utf-8') as f:\n",
        "        for line in f:\n",
        "            try:\n",
        "                tweet = json.loads(line)\n",
        "                if 'content' in tweet:\n",
        "                    mentions = extract_mentions(tweet['content'])\n",
        "                    for mention in mentions:\n",
        "                        mention_counts[mention] += 1\n",
        "            except (json.JSONDecodeError, KeyError):\n",
        "                continue\n",
        "\n",
        "    top_10_mentions = sorted(mention_counts.items(), key=lambda x: x[1], reverse=True)[:10]\n",
        "    return top_10_mentions\n",
        "\n",
        "file_path = \"farmers-protest-tweets-2021-2-4.json\"\n",
        "try:\n",
        "    top_10_mentions = q3_time(file_path)\n",
        "    print(top_10_mentions)\n",
        "except FileNotFoundError:\n",
        "    print(f\"File not found: {file_path}. Please check the file path and try again.\")\n",
        "except json.JSONDecodeError as e:\n",
        "    print(f\"Error parsing JSON file: {e}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OchqRfGfhtQT",
        "outputId": "2ec3c483-69c4-430f-d92b-5c0ffa28b29f"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[('narendramodi', 2261), ('Kisanektamorcha', 1836), ('RakeshTikaitBKU', 1639), ('PMOIndia', 1422), ('RahulGandhi', 1125), ('GretaThunberg', 1046), ('RaviSinghKA', 1015), ('rihanna', 972), ('UNHumanRights', 962), ('meenaharris', 925)]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Desarrollo de Q3 optimizando el uso de memoria"
      ],
      "metadata": {
        "id": "znkR4LcQhzPA"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import json\n",
        "import re\n",
        "from collections import defaultdict\n",
        "from typing import List, Tuple\n",
        "\n",
        "def extract_mentions(text: str) -> List[str]:\n",
        "    # Utilizamos regex para encontrar menciones (@username)\n",
        "    mention_pattern = re.compile(r'@(\\w+)')\n",
        "    return mention_pattern.findall(text)\n",
        "\n",
        "def q3_time(file_path: str) -> List[Tuple[str, int]]:\n",
        "    mention_counts = defaultdict(int)\n",
        "\n",
        "    with open(file_path, 'r', encoding='utf-8') as f:\n",
        "        for line in f:\n",
        "            try:\n",
        "                tweet = json.loads(line)\n",
        "                if 'content' in tweet:\n",
        "                    # Utilizamos generadores para evitar almacenar todos los tweets en memoria\n",
        "                    mentions = extract_mentions(tweet['content'])\n",
        "                    for mention in mentions:\n",
        "                        mention_counts[mention] += 1\n",
        "            except (json.JSONDecodeError, KeyError):\n",
        "                continue\n",
        "\n",
        "    top_10_mentions = sorted(mention_counts.items(), key=lambda x: x[1], reverse=True)[:10] #Se ordenan los ususarios y se obtiene el top 10 con mas interaccioens (Menciones)\n",
        "\n",
        "    # Liberamos memoria explícitamente para mejorar el rendimiento de la memoria\n",
        "    del mention_counts\n",
        "\n",
        "    return top_10_mentions\n",
        "\n",
        "file_path = \"farmers-protest-tweets-2021-2-4.json\"\n",
        "try:\n",
        "    top_10_mentions = q3_time(file_path)\n",
        "    print(top_10_mentions)\n",
        "except FileNotFoundError:\n",
        "    print(f\"File not found: {file_path}. Please check the file path and try again.\")\n",
        "except json.JSONDecodeError as e:\n",
        "    print(f\"Error parsing JSON file: {e}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "d1fgHgZDh0GG",
        "outputId": "3187a250-537a-4ee3-f8f6-ef1eb19ad333"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[('narendramodi', 2261), ('Kisanektamorcha', 1836), ('RakeshTikaitBKU', 1639), ('PMOIndia', 1422), ('RahulGandhi', 1125), ('GretaThunberg', 1046), ('RaviSinghKA', 1015), ('rihanna', 972), ('UNHumanRights', 962), ('meenaharris', 925)]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Explicacion de los codigos para q1, q2 y q3 (**Tiempo de Ejecucion**)\n"
      ],
      "metadata": {
        "id": "Ck_cHeoOQ-Np"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Explicacion de code q1**\n",
        "\n",
        "Se importan las librerias\n",
        "\n",
        "Importa el módulo json para trabajar con archivos JSON.\n",
        "\n",
        "Importa defaultdict del módulo collections para crear diccionarios con valores por defecto, para la comprobacion de los datos y hacer mas eficiente el trabajo con grandes volumenes de datos.\n",
        "\n",
        "from datetime import datetime, date: Importa datetime y date del módulo datetime para trabajar con fechas y horas.\n",
        "\n",
        "from typing import List, Tuple: Importa List y Tuple del módulo typing para anotaciones de tipos, utilizados en la funcion de solucion.\n",
        "\n",
        "Se define la funcion principal y se inicializa el conteo de tweets en 0\n",
        "\n",
        "date_tweet_counts = defaultdict(lambda: defaultdict(int))\n",
        "\n",
        "Se inicializa el archivo json en modo de lectura y se crea un ciclo para recorrer el documento\n",
        "Luego se leen las lineas en busqueda de la fecha de los tweets y el usuario agregando al contador las menciones para cada usuario, controlando la busqueda con try/except con la finalidad de evitar el error en caso de que el formato de los datos no sea el correcto.\n",
        "\n",
        "Se ordenan las fechas de los tweets considerando la cantidad de menciones de menera descendiente y se toman los primeros 10. Luego se entrega el resultado en una lista de tuplas, las cuales contienen la fecha y el usuario.\n",
        "\n",
        "Finalmente, se llama al path del archivo y por medio de try/except se manejan los datos, considerando errores en el path del archivo y posibles errores en el formato de los datos.\n",
        "\n",
        "**Explicacion de code q2**\n",
        "\n",
        "Se utiliza un codigo similar al de la solucion en q1_time, pero se importa el modulo re para trabajar con expresiones regulares.\n",
        "\n",
        "Luego de haber definido el contador de emojis en 0 se utiliza emoji_pattern = re.compile() para encontrar el unicode de los emojis.\n",
        "\n",
        "Luego se realiza el mismo proceso utilizado en q1_time para recorrer el archivo json, encontrarl el top 10 y entregar los resultados.\n",
        "\n",
        "Siempre considerando emplear try/except para manejo de errores\n",
        "\n",
        "**Explicacion de code q3**\n",
        "\n",
        "Se utiliza  una logica similar a las otras dos respuestas la diferencias son pocas y estan netamente enfocadas en la obtencion del username para encontrar al top 10 solicitado\n",
        "\n",
        "mention_pattern = re.compile(r'@(\\w+)'): Compila una expresión regular para encontrar menciones en el formato @username.\n",
        "\n",
        "Se manejas las excepciones de la misma manera y se enfoca en obtener las menciones del usuario, contando directamente esto el el ciclo que recorre el archivo Json.\n",
        "\n",
        "Como se menciono en la linea de codigo mention_pattern, se utiliza una expresion regular que se debe compilar una sola vez y luego solo se reutiliza recorriendo las tuplas dentro de las listas en el archivo con los datos."
      ],
      "metadata": {
        "id": "2j9VqCSrRO0k"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Explicacion de los codigos para q1, q2 y q3 (**Uso de memoria**)\n"
      ],
      "metadata": {
        "id": "hSpaT6e_RJ7v"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Explicacion de code q1**\n",
        "\n",
        "Se importan las librerias\n",
        "\n",
        "Se importan las mismas librerias del q1_time, pero se agrega memory-profiler para medir el uso de memoria del script\n",
        "\n",
        "Se utiliza el decorador @profile para medir el uso de memoria\n",
        "\n",
        "Se define la funcion principal y se inicializa el conteo de tweets en 0\n",
        "\n",
        "date_tweet_counts = defaultdict(lambda: defaultdict(int))\n",
        "\n",
        "Se inicializa el archivo json en modo de lectura y se crea un ciclo para recorrer el documento Luego se leen las lineas en busqueda de la fecha de los tweets y el usuario agregando al contador las menciones para cada usuario, controlando la busqueda con try/except con la finalidad de evitar el error en caso de que el formato de los datos no sea el correcto.\n",
        "\n",
        "Se ordenan las fechas de los tweets considerando la cantidad de menciones de menera descendiente y se toman los primeros 10. Luego se entrega el resultado en una lista de tuplas, las cuales contienen la fecha y el usuario.\n",
        "\n",
        "Finalmente, se llama al path del archivo y por medio de try/except se manejan los datos, considerando errores en el path del archivo y posibles errores en el formato de los datos.\n",
        "\n",
        "**Diferencias principales con q1_time**\n",
        "\n",
        "Se evita la creacion de listas intemedias que pueden ser muy grandes dependiendo del archivo de datos\n",
        "\n",
        "Minimiza el almacenamiento innecesario: Al usar date_tweet_counts.items() para la clasificación, asi evitar almacenar temporalmente una lista completa de fechas, lo que puede ser un ahorro significativo de memoria si el archivo JSON es grande.\n",
        "\n",
        "**Explicacion de code q2**\n",
        "\n",
        "Al igual que q2_time se importan las mismas librerais a diferencia del modulo emoji en su version 1.7 (Por tema de compatibilidad).\n",
        "\n",
        "**Diferencias principales con q2_time**\n",
        "\n",
        "La primera diferencia principal es el uso de la libreria emoji para una funcion extra que comprueba directamente si el caracter es un emoji por medio del unicode de la libreria. Esto optimiza el uso de memoria al ser una comparativa directa y entregar una respuesta booleana.\n",
        "\n",
        "Adicionalmente, para mejorar el uso de memoria se utiliza filter en la funcion creada para verificar si el caracter es un emoji, lo que permite reducir el numero de operaciones realizadas.\n",
        "\n",
        "Finalmente, a pesar que se cubre el mismo rango de caracteres que en q2_time, se validan, procesan y almacenan una menor cantidad de emojis.\n",
        "\n",
        "**Explicacion de code q3**\n",
        "\n",
        "Al igual que en q3_time se importan y trabajan los mismo modulos a diferencia de la libreria que se utiliza para medir el uso de memoria.\n",
        "\n",
        "**Diferencias principales con q3_time**\n",
        "\n",
        "La principal diferencia se encuentra en el uso de del mention_counts con el cual se libera directamente el uso de memoria, lo cual reduce el uso de memoria si un @usename cuenta con muchas menciones en diferentes tweets"
      ],
      "metadata": {
        "id": "O33--M6tgV_H"
      }
    }
  ],
  "metadata": {
    "language_info": {
      "name": "python"
    },
    "orig_nbformat": 4,
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}